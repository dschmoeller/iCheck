{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 15)        150       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 15)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3375)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                33760     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 33,932\n",
      "Trainable params: 33,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the model \n",
    "classifierLoad = tf.keras.models.load_model('./EquationDetector.h5')\n",
    "classifierLoad.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLIDING WINDOW approach --> Crop single pieces of a picture and as for each single one whether there´s a car or not\n",
    "# --> With this approach one can not only ask whethr there´s  a car on the entire picture \n",
    "# but also where the car is actually located on the picture\n",
    "\n",
    "# Window size can be varied in order to deal with \"3D information\" (near cars are bigger than cars which are far away)\n",
    "\n",
    "\n",
    "windowSize = 100\n",
    "step_size = 50\n",
    "whereAreCars = []\n",
    "\n",
    "# Iterate over picture \n",
    "for x in range(0, img.size[0] - windowSize, step_size):\n",
    "    for y in range (0, img.size[1] - windowSize, step_size):\n",
    "        part = img.crop((x, y, x + windowSize, y + windowSize))\n",
    "        #plt.imshow(part)\n",
    "        #plt.show()\n",
    "        # Convert data in order to fit NN input requirement\n",
    "        data = np.asarray(part.resize((32,32), resample = Image.BICUBIC))\n",
    "        data = data.astype(np.float32) / 255.\n",
    "        data = data.reshape(1, 32, 32, 3)\n",
    "        # Ask Neural Network\n",
    "        prediction = carClassifier.predict(data)\n",
    "        #print(\"The probabiity that this slide contains a car is: \", prediction[0][0])\n",
    "        if prediction[0][0] > 0.8: \n",
    "            whereAreCars.append((x, y))\n",
    "            \n",
    "# In which slides (at which coordinates) did the NN predict (i.e. classify) a car?\n",
    "print(whereAreCars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we found a picture, draw the corresponding bounding box\n",
    "# Draw the corresponding slide on the original picture --> Location of car\n",
    "\n",
    "draw = ImageDraw.Draw(copyForDrawing)\n",
    "for car in whereAreCars: \n",
    "    points = [car, (car[0] + windowSize, car[1] + windowSize)]\n",
    "    draw.rectangle(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLIDING WINDOW APPROACH is a verry common approach \n",
    "# Drawback: It takes forever\n",
    "\n",
    "# --> Another concept: YOLO (YOU ONLY LOOK ONCE)\n",
    "# Not that exact but very fast\n",
    "# Approach\n",
    "# Split entire picture into segments\n",
    "# Operate on each single segment (feed it int to CNN)\n",
    "#    --> (1) What is in the segment (probability of car, pedestrian, ...)\n",
    "#    --> (2) Where is the center point and length and width of the corresponding object bounding box \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
